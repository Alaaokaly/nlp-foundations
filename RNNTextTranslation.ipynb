{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alaaokaly/nlp-foundations/blob/main/RNNTextTranslation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4ySAPTd6TAEc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "i-asCDA4UZKv"
      },
      "outputs": [],
      "source": [
        "corpus = \"\"\"Weather in Asia: A Diverse Tapestry of Climates\n",
        "\n",
        "Asia, the largest continent on Earth, is renowned for its immense diversity, not only in culture and geography but also in climate. From the icy tundras of Siberia to the tropical rainforests of Southeast Asia, the weather across this vast expanse varies dramatically. Understanding the climatic conditions in different regions of Asia is essential for agriculture, tourism, and daily life, influencing everything from crop cycles to travel plans.\n",
        "\n",
        "In northern Asia, particularly in Siberia, winters are harsh and long. Temperatures can plummet to as low as -40°C in some areas, making it one of the coldest places on Earth. The vast taiga forest is covered in snow for much of the year, creating a winter wonderland that attracts adventurous tourists. However, summers are brief and can be surprisingly warm, with temperatures reaching 30°C.\n",
        "\n",
        "Moving south, East Asia experiences a different climate, significantly influenced by the monsoon system. Countries like China, Japan, and Korea see seasonal rains that are crucial for agriculture. The summer months bring heavy downpours, often accompanied by typhoons, especially in coastal regions.\n",
        "\n",
        "Southeast Asia is characterized by its tropical climate, with high temperatures and humidity year-round. Countries like Thailand and Indonesia experience two main seasons: the dry season and the wet season. The monsoon rains can lead to flooding but also nourish the lush landscapes.\n",
        "\n",
        "In South Asia, the weather is dominated by the Indian monsoon. The summer monsoon brings heavy rains, crucial for replenishing water supplies and supporting agriculture. However, it can also lead to natural disasters like floods. In contrast, the winter months bring cooler temperatures to northern India.\n",
        "\n",
        "Central Asia, encompassing countries like Kazakhstan and Uzbekistan, is characterized by its continental climate with hot summers and cold winters. The region is largely arid, with deserts dominating the landscape. Despite the harsh conditions, Central Asia has a rich history of nomadic cultures.\n",
        "\n",
        "The weather across Asia is a complex subject, reflecting the continent's vast geographical diversity. Each region has developed its own unique climatic conditions, influencing everything from agriculture to culture. Understanding these dynamics becomes increasingly important as climate change impacts weather patterns globally.\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDQgbizfRz-_",
        "outputId": "af1b809c-e895-4447-bd24-6366dda1b175"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data has 2413 characters, 37 unique.\n"
          ]
        }
      ],
      "source": [
        "data = corpus.lower()\n",
        "chars = list(set(data))\n",
        "data_size, vocab_size = len(data), len(chars)\n",
        "print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
        "\n",
        "char_to_idx = {char: idx for idx, char in enumerate(chars)}\n",
        "idx_to_char = {idx: char for idx, char in enumerate(chars)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gKMAF4nYRE49"
      },
      "outputs": [],
      "source": [
        "# RNN generating text model\n",
        "\n",
        "epochs = 120\n",
        "input_size =  len(chars)\n",
        "output_size =  len(chars)\n",
        "hidden_n = 37\n",
        "sequence_length = 20\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, output_size,hidden_size ):\n",
        "        super(RNN, self).__init__()\n",
        "        self.rnn = nn.RNN(input_size, hidden_n, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, h_0):\n",
        "        out, h_t = self.rnn(x, h_0)\n",
        "        out = self.fc(out[:, -1, :])  # Use only the last output\n",
        "        return out\n",
        "\n",
        "model = RNN(input_size, hidden_n, output_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lnRDu3ClqbEv"
      },
      "outputs": [],
      "source": [
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyWu2yyOrCRG",
        "outputId": "f578da36-515b-4100-e78a-2a01df0182ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch :  0\n",
            "Epoch [1, Loss: 4.3577\n",
            "Epoch :  1\n",
            "Epoch :  2\n",
            "Epoch :  3\n",
            "Epoch :  4\n",
            "Epoch :  5\n",
            "Epoch :  6\n",
            "Epoch :  7\n",
            "Epoch :  8\n",
            "Epoch :  9\n",
            "Epoch :  10\n",
            "Epoch [11, Loss: 1.0240\n",
            "Epoch :  11\n",
            "Epoch :  12\n",
            "Epoch :  13\n",
            "Epoch :  14\n",
            "Epoch :  15\n",
            "Epoch :  16\n",
            "Epoch :  17\n",
            "Epoch :  18\n",
            "Epoch :  19\n",
            "Epoch :  20\n",
            "Epoch [21, Loss: 0.4813\n",
            "Epoch :  21\n",
            "Epoch :  22\n",
            "Epoch :  23\n",
            "Epoch :  24\n",
            "Epoch :  25\n",
            "Epoch :  26\n",
            "Epoch :  27\n",
            "Epoch :  28\n",
            "Epoch :  29\n",
            "Epoch :  30\n",
            "Epoch [31, Loss: 0.6699\n",
            "Epoch :  31\n",
            "Epoch :  32\n",
            "Epoch :  33\n",
            "Epoch :  34\n",
            "Epoch :  35\n",
            "Epoch :  36\n",
            "Epoch :  37\n",
            "Epoch :  38\n",
            "Epoch :  39\n",
            "Epoch :  40\n",
            "Epoch [41, Loss: 0.2703\n",
            "Epoch :  41\n",
            "Epoch :  42\n",
            "Epoch :  43\n",
            "Epoch :  44\n",
            "Epoch :  45\n",
            "Epoch :  46\n",
            "Epoch :  47\n",
            "Epoch :  48\n",
            "Epoch :  49\n",
            "Epoch :  50\n",
            "Epoch [51, Loss: 0.5633\n",
            "Epoch :  51\n",
            "Epoch :  52\n",
            "Epoch :  53\n",
            "Epoch :  54\n",
            "Epoch :  55\n",
            "Epoch :  56\n",
            "Epoch :  57\n",
            "Epoch :  58\n",
            "Epoch :  59\n",
            "Epoch :  60\n",
            "Epoch [61, Loss: 0.0528\n",
            "Epoch :  61\n",
            "Epoch :  62\n",
            "Epoch :  63\n",
            "Epoch :  64\n",
            "Epoch :  65\n",
            "Epoch :  66\n",
            "Epoch :  67\n",
            "Epoch :  68\n",
            "Epoch :  69\n",
            "Epoch :  70\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "    print('Epoch : ', epoch)\n",
        "    for i in range(len(corpus) - sequence_length):\n",
        "\n",
        "        # Prepare input and target sequences\n",
        "        x_seq = [char_to_idx[ch] for ch in data[i:i + sequence_length]]\n",
        "        y_seq = char_to_idx[data[i+sequence_length]]\n",
        "\n",
        "        # Convert to tensor and one-hot encode\n",
        "        x_tensor = torch.zeros(1, sequence_length, vocab_size)\n",
        "        for j, idx in enumerate(x_seq):\n",
        "            x_tensor[0, j, idx] = 1  # One-hot encoding\n",
        "\n",
        "        # Initialize hidden state\n",
        "        h_0 = torch.zeros(1, 1, hidden_n)  # Shape (num_layers, batch_size, hidden_size)\n",
        "\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "        y_pred = model(x_tensor, h_0)  # Get the prediction\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(y_pred, torch.tensor([y_seq]))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    if epoch%10 ==0:\n",
        "        print(f'Epoch [{epoch + 1}, Loss: {loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "w2XYcU-UsmBV",
        "outputId": "c823e46e-524c-430b-8128-0957c7268519"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-142a739ed560>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtest_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"hel\"\u001b[0m  \u001b[0;31m# Take the last 3 characters for prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mx_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mchar_to_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mx_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    test_input = \"hel\"  # Take the last 3 characters for prediction\n",
        "    x_seq = [char_to_idx[ch] for ch in test_input]\n",
        "    x_tensor = torch.zeros(1, sequence_length, vocab_size)\n",
        "    for j, idx in enumerate(x_seq):\n",
        "        x_tensor[0, j, idx] = 1  # One-hot encoding\n",
        "\n",
        "    h_0 = torch.zeros(1, 1, hidden_size)\n",
        "    predicted_output = model(x_tensor, h_0)\n",
        "    predicted_char_idx = torch.argmax(predicted_output).item()\n",
        "    predicted_char = idx_to_char[predicted_char_idx]\n",
        "\n",
        "    print(f\"Input: '{test_input}' -> Predicted next character: '{predicted_char}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGusklbu05qV"
      },
      "outputs": [],
      "source": [
        "# evaluate using preplexity"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMA7JQmlHwB5kVr0CHCHwdI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}